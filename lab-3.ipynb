{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Description**\n",
        "<p align=\"justify\">\n",
        "Python script bellow creates neural network model for solving simple classification problem. Dataset is loaded from CSV files, and data values are numerical. Data rows represent wine characteristics, and model classify wine as white or red based on its characteristics.\n",
        "</p>"
      ],
      "metadata": {
        "id": "rILQMpI8M4_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "# LOADING DATA FROM CSV FILES\n",
        "# Ajust file paths!\n",
        "redWines = pd.read_csv(\"/content/red-wine-quality.csv\", sep = \";\")\n",
        "whiteWines = pd.read_csv(\"/content/white-wine-quality.csv\", sep = \";\")\n",
        "\n",
        "\n",
        "# ADDING COLUMN WITH DATA LABELS\n",
        "redWines[\"label\"] = 1\n",
        "whiteWines[\"label\"] = 0\n",
        "\n",
        "# CONCATENATING DATA INTO ONE DataFrame OBJECT\n",
        "wines = pd.concat([whiteWines, redWines])\n",
        "\n",
        "# ANALYSING DATASET\n",
        "#wines.describe()\n",
        "#wines.hist()\n",
        "\n",
        "# SPLITTING DATA INTO CHARACTERISTICS AND LABELS\n",
        "y = wines[\"label\"]\n",
        "x = wines.drop(columns = [\"label\"]) \n",
        "\n",
        "# SPLITTING DATASET INTO TRAINING AND TESTING SETS\n",
        "xTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size = 0.2)\n",
        "\n",
        "# STANDARDIZING DATA VALUES\n",
        "standardScaler = StandardScaler().fit(xTrain)\n",
        "xTrain = standardScaler.transform(xTrain)\n",
        "xTest = standardScaler.transform(xTest)\n",
        "\n",
        "# CREATING NEURAL NETWORK MODEL\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(8, activation = \"relu\", input_shape = (12,)))\n",
        "model.add(layers.Dense(8, activation = \"relu\"))\n",
        "model.add(layers.Dense(1, activation = \"sigmoid\"))\n",
        "\n",
        "# COMPILING NEURAL NETWORK MODEL\n",
        "model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
        "\n",
        "# NEURAL NETWORK MODEL TRAINING\n",
        "trainingHistory = model.fit(xTrain, yTrain, epochs = 20, batch_size = 16)\n",
        "\n",
        "# EVALUATING NEURAL NETWORK MODEL\n",
        "evaluatingResults = model.evaluate(xTest, yTest)"
      ],
      "metadata": {
        "id": "YSTS30fbQP9n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}